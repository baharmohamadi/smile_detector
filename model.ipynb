{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51154994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0fe58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
       "0  000001.jpg                -1                1           1               -1   \n",
       "1  000002.jpg                -1               -1          -1                1   \n",
       "2  000003.jpg                -1               -1          -1               -1   \n",
       "3  000004.jpg                -1               -1           1               -1   \n",
       "4  000005.jpg                -1                1           1               -1   \n",
       "\n",
       "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  Sideburns  Smiling  \\\n",
       "0    -1     -1        -1        -1          -1  ...         -1        1   \n",
       "1    -1     -1        -1         1          -1  ...         -1        1   \n",
       "2    -1     -1         1        -1          -1  ...         -1       -1   \n",
       "3    -1     -1        -1        -1          -1  ...         -1       -1   \n",
       "4    -1     -1         1        -1          -1  ...         -1       -1   \n",
       "\n",
       "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
       "0              1         -1                 1           -1                 1   \n",
       "1             -1         -1                -1           -1                -1   \n",
       "2             -1          1                -1           -1                -1   \n",
       "3              1         -1                 1           -1                 1   \n",
       "4             -1         -1                -1           -1                 1   \n",
       "\n",
       "   Wearing_Necklace  Wearing_Necktie  Young  \n",
       "0                -1               -1      1  \n",
       "1                -1               -1      1  \n",
       "2                -1               -1      1  \n",
       "3                 1               -1      1  \n",
       "4                -1               -1      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = pd.read_csv(r\"2\\img_align_celeba\\list_attr_celeba.csv\")\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'2\\img_align_celeba\\img_align_celeba'\n",
    "\n",
    "image_extensions = ('.jpg')\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for filename, y in zip(os.listdir(folder_path)[:25000], Y[\"Smiling\"]):\n",
    "    image_path = os.path.join(folder_path, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is not None:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        images.append(image)\n",
    "        labels.append(y)\n",
    "    else:\n",
    "        print(f\"Warning: Failed to load {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 if x == -1 else x for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001dd275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    images, labels, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e041e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop([178, 178]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop([178, 178]),\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1697a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.to_pil = ToPILImage()\n",
    "\n",
    "        if self.transform:\n",
    "            # Apply transform once to all images and store them\n",
    "            self.images = torch.stack([\n",
    "                self.transform(self.to_pil(img)) for img in images\n",
    "            ])\n",
    "        else:\n",
    "            self.images = images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorImageDataset(X_train, y_train, transform=transform_train)\n",
    "val_dataset = TensorImageDataset(X_val, y_val, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ed4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "mini_batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, mini_batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, mini_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00602fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    # B, 3, 64, 64\n",
    "    nn.Conv2d(\n",
    "        in_channels=3, \n",
    "        out_channels=32,\n",
    "        kernel_size=3, \n",
    "        padding=1\n",
    "    ),\n",
    "    # B, 32, 62, 62\n",
    "    nn.ReLU(),\n",
    "    # B, 32, 62, 62\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    # B, 32, 31, 31\n",
    "    # nn.Dropout2d(p=0.5),\n",
    "    # B, 32, 31, 31\n",
    "    nn.Conv2d(\n",
    "        in_channels=32, \n",
    "        out_channels=128,\n",
    "        kernel_size=3, \n",
    "        padding=1\n",
    "    ),\n",
    "    nn.BatchNorm2d(128),\n",
    "    # B, 128, 30, 30\n",
    "    nn.ReLU(),\n",
    "    # B, 128, 30, 30\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    # B, 128, 15, 15\n",
    "    # nn.Dropout2d(p=0.5),\n",
    "    # B, 128, 15, 15\n",
    "    nn.Conv2d(\n",
    "        in_channels=128,\n",
    "        out_channels=256,\n",
    "        kernel_size=3,\n",
    "        padding=1\n",
    "    ),\n",
    "    nn.BatchNorm2d(256),\n",
    "    # B, 256, 14, 14\n",
    "    nn.ReLU(),\n",
    "    # B, 256, 14, 14\n",
    "    nn.MaxPool2d(kernel_size=2),\n",
    "    # B, 256, 7, 7\n",
    "    nn.Conv2d(\n",
    "        in_channels=256,\n",
    "        out_channels=256,\n",
    "        kernel_size=3,\n",
    "        padding=1\n",
    "    ),\n",
    "    nn.BatchNorm2d(256),\n",
    "    # B, 256, 6, 6\n",
    "    nn.ReLU(),\n",
    "    # B, 256, 6, 6\n",
    "    nn.AvgPool2d(kernel_size=8),\n",
    "    # B, 256, 1, 1\n",
    "    nn.Flatten(),\n",
    "    # B, 256 * 1 * 1\n",
    "    nn.Linear(256, 1)\n",
    ")\n",
    "\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4fe775",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0021\n",
      "Epoch 2, Loss: 0.0021\n",
      "Epoch 3, Loss: 0.0018\n",
      "Epoch 4, Loss: 0.0024\n",
      "Epoch 5, Loss: 0.0019\n",
      "Epoch 5, Validation Accuracy: 85.45%\n",
      "Epoch 6, Loss: 0.0018\n",
      "Epoch 7, Loss: 0.0015\n",
      "Epoch 8, Loss: 0.0013\n",
      "Epoch 9, Loss: 0.0016\n",
      "Epoch 10, Loss: 0.0014\n",
      "Epoch 10, Validation Accuracy: 84.53%\n",
      "Epoch 11, Loss: 0.0012\n",
      "Epoch 12, Loss: 0.0013\n",
      "Epoch 13, Loss: 0.0011\n",
      "Epoch 14, Loss: 0.0011\n",
      "Epoch 15, Loss: 0.0010\n",
      "Epoch 15, Validation Accuracy: 86.74%\n",
      "Epoch 16, Loss: 0.0008\n",
      "Epoch 17, Loss: 0.0010\n",
      "Epoch 18, Loss: 0.0013\n",
      "Epoch 19, Loss: 0.0008\n",
      "Epoch 20, Loss: 0.0009\n",
      "Epoch 20, Validation Accuracy: 86.56%\n",
      "Epoch 21, Loss: 0.0009\n",
      "Epoch 22, Loss: 0.0008\n",
      "Epoch 23, Loss: 0.0008\n",
      "Epoch 24, Loss: 0.0008\n",
      "Epoch 25, Loss: 0.0007\n",
      "Epoch 25, Validation Accuracy: 86.37%\n",
      "Epoch 26, Loss: 0.0006\n",
      "Epoch 27, Loss: 0.0006\n",
      "Epoch 28, Loss: 0.0007\n",
      "Epoch 29, Loss: 0.0005\n",
      "Epoch 30, Loss: 0.0005\n",
      "Epoch 30, Validation Accuracy: 86.00%\n"
     ]
    }
   ],
   "source": [
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to('cuda').float()\n",
    "            y_batch = y_batch.to('cuda').float()\n",
    "            pred = model(x_batch).squeeze(1)\n",
    "\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                li = loss.item()\n",
    "                # print(li)\n",
    "                losses.append(li)\n",
    "                \n",
    "        print(f'Epoch {epoch+1}, Loss: {np.mean(losses):.4f}')\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for x_batch, y_batch in valid_dl:\n",
    "                    x_batch = x_batch.to('cuda').float()\n",
    "                    y_batch = y_batch.to('cuda').float()\n",
    "                    pred = model(x_batch).squeeze(1)\n",
    "                    predicted = (pred > 0.5).float()\n",
    "                    total += y_batch.size(0)\n",
    "                    correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "                accuracy = 100 * correct / total\n",
    "                print(f'Epoch {epoch+1}, Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 30\n",
    "train(model, num_epochs, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
